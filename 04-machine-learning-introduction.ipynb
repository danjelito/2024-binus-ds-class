{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning\n",
    "\n",
    "Machine Learning (ML) is a branch of artificial intelligence that enables computers to learn from data and make decisions without being explicitly programmed.\n",
    "\n",
    "It is widely used in various applications, from recommendation systems to image recognition.\n",
    "\n",
    "In this introduction, we will explore fundamental concepts of machine learning, including supervised and unsupervised learning, training and test sets, scoring, and a brief overview of common ML algorithms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Machine Learning?\n",
    "\n",
    "Machine learning involves the development of algorithms that can learn patterns from data.\n",
    "\n",
    "The primary goal is to make predictions or decisions based on input data.\n",
    "\n",
    "ML can be broadly categorized into two main types: **Supervised Learning** and **Unsupervised Learning**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Supervised vs. Unsupervised Learning\n",
    "\n",
    "**Supervised Learning**:\n",
    "\n",
    "- In supervised learning, the model is trained on a labeled dataset, which means that the input data is paired with the correct output (label).\n",
    "\n",
    "- The model learns to map inputs to outputs and is evaluated based on its ability to predict labels for new, unseen data.\n",
    "\n",
    "- **Examples:** Linear regression, logistic regression, decision trees, and support vector machines.\n",
    "\n",
    "**Unsupervised Learning**:\n",
    "\n",
    "- In unsupervised learning, the model is trained on data without labeled outputs.\n",
    "\n",
    "- The goal is to identify patterns, group similar data points, or reduce dimensionality.\n",
    "\n",
    "- **Examples:** K-means clustering, hierarchical clustering, and principal component analysis (PCA).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Classification vs. Regression\n",
    "\n",
    "Classification and regression are two fundamental types of supervised learning tasks in machine learning, each serving different purposes and involving different types of outputs. Here’s a detailed comparison:\n",
    "\n",
    "### 1. **Definition**\n",
    "\n",
    "- **Classification**: This is a type of supervised learning where the goal is to predict a discrete label or category based on input features. The model learns to assign new data points to one of the predefined classes.\n",
    "- **Regression**: This is another type of supervised learning where the goal is to predict a continuous numeric value based on input features. The model learns to estimate the relationship between input variables and a continuous output.\n",
    "\n",
    "### 2. **Output Type**\n",
    "\n",
    "- **Classification**: The output is categorical. It can be binary (e.g., yes/no, spam/not spam) or multiclass (e.g., classifying animals into categories like dog, cat, or bird).\n",
    "- **Regression**: The output is continuous. Examples include predicting prices, temperatures, or any numerical value.\n",
    "\n",
    "### 3. **Use Cases**\n",
    "\n",
    "- **Classification Use Cases**:\n",
    "  - **Spam Detection**: Classifying emails as spam or not spam.\n",
    "  - **Sentiment Analysis**: Classifying text (like tweets or reviews) as positive, negative, or neutral.\n",
    "  - **Image Recognition**: Identifying objects in images (e.g., classifying images of animals).\n",
    "- **Regression Use Cases**:\n",
    "  - **House Price Prediction**: Predicting the selling price of a house based on features like size, location, and age.\n",
    "  - **Stock Price Forecasting**: Predicting future stock prices based on historical data.\n",
    "  - **Weather Forecasting**: Estimating the temperature or rainfall for the upcoming days.\n",
    "\n",
    "### 4. **Example**\n",
    "\n",
    "- **Classification Example**:\n",
    "  - Given a dataset of emails with features (like word counts, presence of specific words), classify them into \"spam\" or \"not spam\".\n",
    "- **Regression Example**:\n",
    "  - Given a dataset of houses with features (like size, number of rooms), predict the price of a new house based on those features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training and Test Sets\n",
    "\n",
    "When developing a machine learning model, the dataset is typically divided into two parts:\n",
    "\n",
    "- **Training Set**: This portion of the data is used to train the model. The model learns the relationships between the input features and the output labels.\n",
    "\n",
    "- **Test Set**: This portion is used to evaluate the performance of the model. It contains data that the model has never seen before, allowing for an unbiased assessment of how well the model generalizes to new data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      " [[ 9 10]\n",
      " [ 5  6]\n",
      " [ 1  2]\n",
      " [ 7  8]]\n",
      "y_train:\n",
      " [0 0 0 1]\n",
      "X_test:\n",
      " [[3 4]]\n",
      "y_test:\n",
      " [1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Example dataset\n",
    "X = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]])  # Features\n",
    "y = np.array([0, 1, 0, 1, 0])  # Labels\n",
    "\n",
    "# Split the dataset into training and test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"X_train:\\n\", X_train)\n",
    "print(\"y_train:\\n\", y_train)\n",
    "print(\"X_test:\\n\", X_test)\n",
    "print(\"y_test:\\n\", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Encoding Categorival Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning, models require numerical inputs. If your dataset contains **categorical variables** (i.e., non-numeric data like \"red,\" \"blue,\" or \"green\"), you need to **encode** these into numbers for the model to understand. \n",
    "\n",
    "There are two main ways to encode categorical variables:\n",
    "\n",
    "### 1. **Label Encoding**\n",
    "- Assigns each unique category a different numerical value.\n",
    "- Example: For a \"Color\" column with values \"Red,\" \"Blue,\" and \"Green,\" it might assign:\n",
    "    - Red → 0\n",
    "    - Blue → 1\n",
    "    - Green → 2\n",
    "- Useful when the categorical variable has an **inherent order** (e.g., \"Low,\" \"Medium,\" \"High\").\n",
    "\n",
    "### 2. **One-Hot Encoding**\n",
    "- Converts each category into a new binary column.\n",
    "- Each column represents whether the category is present (1) or not (0).\n",
    "- Example: For \"Color,\" it creates separate columns like:\n",
    "    - Red: [1, 0, 0]\n",
    "    - Blue: [0, 1, 0]\n",
    "    - Green: [0, 0, 1]\n",
    "- Best for **unordered categories** (no ranking).\n",
    "\n",
    "**Example Code for Encoding with Pandas**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Color  Color_Label\n",
      "0    Red            2\n",
      "1   Blue            0\n",
      "2  Green            1\n",
      "3   Blue            0\n",
      "4    Red            2\n",
      "   Color_Blue  Color_Green  Color_Red\n",
      "0       False        False       True\n",
      "1        True        False      False\n",
      "2       False         True      False\n",
      "3        True        False      False\n",
      "4       False        False       True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Sample data\n",
    "df = pd.DataFrame({'Color': ['Red', 'Blue', 'Green', 'Blue', 'Red']})\n",
    "\n",
    "# Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "df['Color_Label'] = label_encoder.fit_transform(df['Color'])\n",
    "\n",
    "# One-Hot Encoding\n",
    "df_one_hot = pd.get_dummies(df['Color'], prefix='Color')\n",
    "\n",
    "print(df)\n",
    "print(df_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing an Encoding Method:\n",
    "- **Label Encoding**: When the categories have some natural order (e.g., \"Beginner,\" \"Intermediate,\" \"Advanced\").\n",
    "- **One-Hot Encoding**: When categories are unordered and you're not interested in any implicit ranking.\n",
    "\n",
    "Both methods help convert non-numeric data into a format that machine learning algorithms can work with!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Scaling and Normalizing Data in Machine Learning\n",
    "\n",
    "Machine learning algorithms often perform better when the input features (data) are on a similar scale. **Scaling** and **normalizing** are techniques used to achieve this.\n",
    "\n",
    "### 1. **Scaling**\n",
    "Scaling changes the range of the data. It ensures that all features contribute equally to the model, especially when they are measured in different units (e.g., age vs. income).\n",
    "\n",
    "#### Common Scaling Methods:\n",
    "\n",
    "- **Min-Max Scaling**: Scales the data to a specific range, usually between 0 and 1.\n",
    "  - Formula:  \n",
    "    $$ X_{scaled} = \\frac{X - X_{min}}{X_{max} - X_{min}} $$\n",
    "  - Useful when you know the upper and lower bounds of your data.\n",
    "\n",
    "- **Standardization (Z-score Scaling)**: Scales data so it has a mean of 0 and a standard deviation of 1.\n",
    "  - Formula:  \n",
    "    $$ X_{standard} = \\frac{X - \\mu}{\\sigma} $$\n",
    "  - Best when your data follows a normal distribution (bell curve).\n",
    "\n",
    "### 2. **Normalization**\n",
    "Normalization converts data to a unit norm (length of 1). It’s useful when you want to ensure that the magnitude of the feature does not impact the model.\n",
    "\n",
    "#### Common Normalization Method:\n",
    "- **L2 Normalization**: Scales the values so the sum of squares of the values is 1.  \n",
    "  $$ X_{norm} = \\frac{X}{||X||_2} $$\n",
    "  \n",
    "  It’s often used in algorithms like K-Nearest Neighbors or when working with sparse data (e.g., text data).\n",
    "\n",
    "### Choosing Scaling vs. Normalizing:\n",
    "\n",
    "- **Scaling** is commonly used in algorithms like support vector machines, linear regression, or neural networks that assume features on a similar scale.\n",
    "- **Normalization** is often applied in algorithms like K-Nearest Neighbors (KNN) or Principal Component Analysis (PCA), where the magnitude of data can affect performance.\n",
    "\n",
    "By using these techniques, your machine learning model can learn more efficiently and avoid giving more weight to certain features over others!\n",
    "\n",
    "**Example Code for Scaling and Normalizing**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Income\n",
       "0   25   40000\n",
       "1   45   80000\n",
       "2   35   60000\n",
       "3   50  120000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, normalize\n",
    "\n",
    "# Sample data\n",
    "df = pd.DataFrame({\n",
    "    'Age': [25, 45, 35, 50],\n",
    "    'Income': [40000, 80000, 60000, 120000]\n",
    "})\n",
    "\n",
    "print(\"Original Data:\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Income\n",
       "0  0.0    0.00\n",
       "1  0.8    0.50\n",
       "2  0.4    0.25\n",
       "3  1.0    1.00"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Min-Max Scaling\n",
    "min_max_scaler = MinMaxScaler()\n",
    "df_min_max_scaled = pd.DataFrame(min_max_scaler.fit_transform(df), columns=df.columns)\n",
    "df_min_max_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.432078</td>\n",
       "      <td>-1.183216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.650945</td>\n",
       "      <td>0.169031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.390567</td>\n",
       "      <td>-0.507093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.171700</td>\n",
       "      <td>1.521278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age    Income\n",
       "0 -1.432078 -1.183216\n",
       "1  0.650945  0.169031\n",
       "2 -0.390567 -0.507093\n",
       "3  1.171700  1.521278"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardization (Z-score Scaling)\n",
    "standard_scaler = StandardScaler()\n",
    "df_standardized = pd.DataFrame(standard_scaler.fit_transform(df), columns=df.columns)\n",
    "df_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000625</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000562</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000583</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000417</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  Income\n",
       "0  0.000625     1.0\n",
       "1  0.000562     1.0\n",
       "2  0.000583     1.0\n",
       "3  0.000417     1.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalization (L2 Norm)\n",
    "df_normalized = pd.DataFrame(normalize(df, norm='l2'), columns=df.columns)\n",
    "df_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Scoring\n",
    "\n",
    "Scoring refers to the process of evaluating the performance of a machine learning model using metrics that quantify its accuracy, precision, recall, and other relevant measures. Proper scoring helps in understanding how well the model is performing and guides improvements.\n",
    "\n",
    "### Confusion Matrix\n",
    "\n",
    "A confusion matrix is a table used to evaluate the performance of a classification model by comparing predicted values with actual values. It summarizes the results into four categories:\n",
    "\n",
    "| Metric         | Definition                                                                 |\n",
    "|----------------|---------------------------------------------------------------------------|\n",
    "| True Positive   | Correctly predicted positive cases (TP)                                   |\n",
    "| True Negative   | Correctly predicted negative cases (TN)                                   |\n",
    "| False Positive  | Incorrectly predicted positive cases (FP) (Type I error)                 |\n",
    "| False Negative  | Incorrectly predicted negative cases (FN) (Type II error)                |\n",
    "\n",
    "#### Example\n",
    "\n",
    "Consider a binary classification model that predicts whether an email is spam (positive) or not spam (negative):\n",
    "\n",
    "- **True Positive (TP)**: The model predicts an email is spam, and it is indeed spam.\n",
    "- **True Negative (TN)**: The model predicts an email is not spam, and it is indeed not spam.\n",
    "- **False Positive (FP)**: The model predicts an email is spam, but it is actually not spam (a legitimate email marked as spam).\n",
    "- **False Negative (FN)**: The model predicts an email is not spam, but it is actually spam (a spam email that was missed).\n",
    "\n",
    "\n",
    "### Classification Metrics\n",
    "\n",
    "Common metrics for classification include:\n",
    "\n",
    "- **Accuracy**: The proportion of correctly predicted instances among all instances. It is calculated as:\n",
    "  $$\n",
    "  \\text{Accuracy} = \\frac{\\text{True Positives} + \\text{True Negatives}}{\\text{Total Instances}}\n",
    "  $$\n",
    "- **Precision**: The proportion of true positive predictions to the total predicted positives. It is calculated as:\n",
    "\n",
    "  $$\n",
    "  \\text{Precision} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Positives}}\n",
    "  $$\n",
    "\n",
    "  This metric is crucial in scenarios where false positives are costly.\n",
    "\n",
    "- **Recall (Sensitivity)**: The proportion of true positive predictions to the total actual positives. It is calculated as:\n",
    "\n",
    "  $$\n",
    "  \\text{Recall} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Negatives}}\n",
    "  $$\n",
    "\n",
    "  Recall is important when the focus is on minimizing false negatives.\n",
    "\n",
    "- **F1 Score**: The harmonic mean of precision and recall, providing a balance between the two. It is calculated as:\n",
    "\n",
    "  $$\n",
    "  \\text{F1 Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "  $$\n",
    "\n",
    "  This metric is useful when you need to find an optimal balance between precision and recall.\n",
    "\n",
    "- **Confusion Matrix**: A table that describes the performance of a classification model. It provides counts of true positives, false positives, true negatives, and false negatives. This matrix can help identify where the model is making errors.\n",
    "\n",
    "### Regression Metrics\n",
    "\n",
    "Common metrics for regression include:\n",
    "\n",
    "- **Mean Absolute Error (MAE)**: The average absolute difference between predicted and actual values. It is calculated as:\n",
    "\n",
    "  $$\n",
    "  \\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|\n",
    "  $$\n",
    "\n",
    "  MAE provides a straightforward measure of error in the same units as the output variable.\n",
    "\n",
    "- **Mean Squared Error (MSE)**: The average of the squares of the differences between predicted and actual values. It is calculated as:\n",
    "\n",
    "  $$\n",
    "  \\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
    "  $$\n",
    "\n",
    "  MSE penalizes larger errors more than smaller ones, making it sensitive to outliers.\n",
    "\n",
    "- **Root Mean Squared Error (RMSE)**: The square root of the mean squared error, providing error in the same units as the output variable. It is calculated as:\n",
    "\n",
    "  $$\n",
    "  \\text{RMSE} = \\sqrt{\\text{MSE}}\n",
    "  $$\n",
    "\n",
    "  RMSE is often used to interpret the model's performance in a more intuitive manner.\n",
    "\n",
    "- **R-squared (R²)**: Indicates the proportion of variance in the dependent variable that can be explained by the independent variables. It is calculated as:\n",
    "  $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Overview of Machine Learning Algorithms\n",
    "\n",
    "Various algorithms can be used for machine learning tasks, each with its strengths and weaknesses.\n",
    "\n",
    "Here are a few common algorithms:\n",
    "\n",
    "- **Linear Regression**: Used for predicting continuous values based on linear relationships between input features.\n",
    "\n",
    "- **Logistic Regression**: Used for binary classification tasks where the output is categorical (0 or 1).\n",
    "\n",
    "- **Decision Trees**: A non-linear model that splits data into branches to make predictions based on feature values.\n",
    "\n",
    "- **Random Forest**: An ensemble method that combines multiple decision trees to improve accuracy and reduce overfitting.\n",
    "\n",
    "- **K-Means Clustering**: An unsupervised learning algorithm used for partitioning data into k clusters based on similarity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Supervised Learning with Scikit-Learn\n",
    "\n",
    "In this example, we will use the Scikit-Learn library to demonstrate a simple supervised learning task using the Iris dataset. We will build a classification model to predict the species of iris flowers based on their features.\n",
    "\n",
    "**Example Code:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Decision Tree model: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data  # Features (sepal length, sepal width, petal length, petal width)\n",
    "y = iris.target  # Labels (species)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create a Decision Tree classifier\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Train the model on the training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy of the Decision Tree model:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
